{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {\"doc_key\": \"mz\", \"sentences\": [[\"[CLS]\", \"At\", \"the\", \"moment\", \",\", \"it\", \"may\", \"be\", \"difficult\", \"to\", \"imagine\", \",\", \"but\", \"many\", \"people\", \"believe\", \"that\", \",\", \"by\", \"the\", \"year\", \"212\", \"##0\", \",\", \"we\", \"will\", \"live\", \"on\", \"the\", \"planet\", \"Mars\", \".\", \"Our\", \"own\", \"planet\", \",\", \"Earth\", \",\", \"is\", \"becoming\", \"more\", \"and\", \"more\", \"crow\", \"##ed\", \"and\", \"poll\", \"##uted\", \".\", \"Luckily\", \",\", \"we\", \"can\", \"start\", \"again\", \"and\", \"build\", \"a\", \"better\", \"world\", \"on\", \"Mars\", \".\", \"Here\", \"is\", \"what\", \"life\", \"could\", \"be\", \"like\", \".\", \"First\", \"of\", \"all\", \",\", \"transport\", \"should\", \"be\", \"much\", \"better\", \".\", \"At\", \"present\", \",\", \"our\", \"spaces\", \"##hips\", \"are\", \"too\", \"slow\", \"to\", \"carry\", \"large\", \"numbers\", \"of\", \"people\", \"to\", \"Mars\", \"-\", \"-\", \"it\", \"takes\", \"months\", \".\", \"However\", \",\", \"by\", \"210\", \"##0\", \",\", \"spaces\", \"##hip\", \"can\", \"travel\", \"at\", \"half\", \"the\", \"speed\", \"of\", \"light\", \".\", \"It\", \"might\", \"take\", \"us\", \"two\", \"or\", \"three\", \"days\", \"to\", \"get\", \"to\", \"Mars\", \"!\", \"Second\", \"##ly\", \",\", \"humans\", \"need\", \"food\", \",\", \"water\", \"and\", \"air\", \"to\", \"live\", \".\", \"Scientists\", \"should\", \"be\", \"able\", \"to\", \"develop\", \"plants\", \"that\", \"can\", \"be\", \"grown\", \"on\", \"Mars\", \".\", \"These\", \"plants\", \"will\", \"produce\", \"the\", \"food\", \"and\", \"air\", \"that\", \"we\", \"need\", \".\", \"However\", \",\", \"can\", \"these\", \"plants\", \"produce\", \"water\", \"for\", \"us\", \"?\", \"There\", \"is\", \"no\", \"answer\", \"now\", \".\", \"There\", \"is\", \"a\", \"problem\", \"for\", \"us\", \"to\", \"live\", \"on\", \"Mars\", \".\", \"Mars\", \"pulls\", \"us\", \"much\", \"less\", \"than\", \"the\", \"Earth\", \"does\", \".\", \"This\", \"will\", \"be\", \"dangerous\", \"because\", \"we\", \"could\", \"easily\", \"jump\", \"too\", \"high\", \"and\", \"fly\", \"slowly\", \"away\", \"into\", \"space\", \".\", \"To\", \"prevent\", \"this\", \",\", \"humans\", \"on\", \"Mars\", \"have\", \"to\", \"wear\", \"special\", \"shoes\", \"to\", \"make\", \"themselves\", \"heavier\", \".\", \"Life\", \"on\", \"Mars\", \"will\", \"be\", \"better\", \"than\", \"that\", \"on\", \"Earth\", \"in\", \"many\", \"ways\", \",\", \"People\", \"will\", \"have\", \"more\", \"space\", \".\", \"Living\", \"in\", \"a\", \"large\", \"building\", \"with\", \"only\", \"10\", \"bedrooms\", \"is\", \"highly\", \"possible\", \".\", \"Many\", \"people\", \"believe\", \"that\", \"robot\", \"will\", \"do\", \"most\", \"of\", \"our\", \"work\", \",\", \"so\", \"we\", \"have\", \"more\", \"time\", \"for\", \"our\", \"ho\", \"##bb\", \"##ies\", \".\", \"There\", \"will\", \"probably\", \"be\", \"no\", \"school\", \"on\", \"Mars\", \".\", \"Every\", \"student\", \"will\", \"have\", \"a\", \"computer\", \"at\", \"home\", \"which\", \"is\", \"connected\", \"to\", \"the\", \"internet\", \".\", \"They\", \"can\", \"study\", \",\", \"do\", \"their\", \"homework\", \"and\", \"take\", \"exams\", \"in\", \"online\", \"schools\", \".\", \"Each\", \"student\", \"will\", \"also\", \"have\", \"their\", \"own\", \"online\", \"teacher\", \"called\", \"`\", \"`\", \"e\", \"-\", \"teacher\", \"'\", \"'\", \".\", \"However\", \",\", \"in\", \"some\", \"ways\", \",\", \"life\", \"on\", \"Mars\", \"may\", \"not\", \"be\", \"better\", \"than\", \"that\", \"on\", \"the\", \"earth\", \"today\", \".\", \"[SEP]\"], [\"[CLS]\", \"Food\", \"will\", \"not\", \"be\", \"the\", \"same\", \"-\", \"-\", \"meals\", \"will\", \"probably\", \"be\", \"in\", \"the\", \"form\", \"of\", \"pills\", \"and\", \"will\", \"not\", \"be\", \"as\", \"delicious\", \"as\", \"they\", \"are\", \"today\", \",\", \"Also\", \",\", \"space\", \"travel\", \"will\", \"make\", \"many\", \"people\", \"feel\", \"ill\", \".\", \"The\", \"spaces\", \"##hip\", \"will\", \"travel\", \"fast\", \"but\", \"the\", \"journey\", \"to\", \"Mars\", \"will\", \"probably\", \"be\", \"very\", \"uncomfortable\", \".\", \"[SEP]\"]], \"speakers\": [[\"[SPL]\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"[SPL]\"], [\"[SPL]\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"[SPL]\"]], \"clusters\": [], \"sentence_map\": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 25, 25, 25, 25, 25, 25, 25, 25, 25, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 31], \"subtoken_map\": [0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 41, 42, 43, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 93, 94, 95, 96, 97, 98, 99, 100, 101, 101, 102, 103, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 288, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 338, 339, 339, 339, 340, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 361, 362, 362, 363, 364, 365, 366, 367, 368, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 415], \"predicted_clusters\": [[[24, 24], [32, 32], [51, 51], [84, 84], [124, 124], [170, 170], [181, 181], [194, 194], [202, 202], [215, 215], [287, 287], [291, 291], [296, 296]], [[28, 30], [61, 61], [97, 97], [132, 132], [159, 159], [198, 198], [200, 200], [234, 234], [247, 247], [308, 308], [365, 365], [428, 428]], [[19, 22], [107, 108]], [[153, 159], [161, 162], [176, 177]], [[32, 36], [206, 207], [254, 254], [373, 374]], [[201, 201], [210, 210]], [[222, 222], [230, 230]], [[232, 234], [242, 242]], [[310, 311], [325, 325], [330, 330]], [[339, 340], [344, 344]], [[387, 387], [403, 403]], [[375, 375], [405, 405]]], \"top_spans\": [[1, 15], [5, 5], [5, 10], [5, 15], [13, 14], [13, 15], [15, 15], [19, 22], [19, 30], [24, 24], [26, 26], [28, 30], [32, 32], [32, 36], [32, 37], [32, 47], [51, 51], [56, 56], [61, 61], [63, 63], [66, 66], [68, 68], [71, 73], [71, 77], [71, 79], [75, 75], [77, 77], [81, 82], [84, 84], [84, 86], [84, 97], [84, 102], [91, 91], [92, 95], [97, 97], [100, 100], [107, 108], [107, 119], [110, 111], [110, 119], [113, 113], [121, 121], [124, 124], [130, 130], [132, 132], [134, 135], [134, 138], [137, 137], [138, 138], [139, 143], [139, 145], [145, 145], [147, 147], [149, 152], [152, 152], [153, 159], [157, 157], [159, 159], [161, 162], [161, 171], [165, 171], [170, 170], [170, 171], [176, 177], [176, 181], [181, 181], [183, 183], [189, 189], [191, 198], [194, 194], [194, 198], [196, 196], [198, 198], [200, 200], [200, 202], [200, 208], [201, 201], [201, 202], [202, 202], [206, 207], [206, 208], [210, 210], [210, 226], [215, 215], [215, 226], [222, 222], [226, 226], [230, 230], [232, 234], [232, 243], [234, 234], [235, 235], [237, 237], [238, 239], [242, 242], [242, 243], [245, 247], [245, 261], [247, 247], [249, 249], [254, 254], [259, 259], [259, 261], [261, 261], [265, 265], [267, 273], [271, 273], [274, 274], [278, 279], [278, 280], [278, 299], [280, 280], [281, 282], [281, 299], [284, 284], [287, 287], [287, 288], [287, 299], [291, 291], [291, 299], [296, 296], [296, 298], [296, 299], [301, 301], [303, 303], [308, 308], [310, 311], [310, 313], [310, 323], [312, 313], [313, 313], [314, 315], [314, 323], [320, 320], [322, 323], [325, 325], [327, 327], [330, 330], [330, 331], [336, 337], [339, 340], [339, 343], [342, 343], [344, 344], [344, 355], [344, 356], [355, 355], [363, 365], [365, 365], [373, 374], [373, 375], [373, 376], [373, 377], [375, 375], [379, 379], [385, 412], [387, 387], [387, 405], [387, 410], [389, 389], [389, 390], [390, 390], [403, 403], [403, 405], [405, 405], [409, 410], [412, 412], [413, 414], [418, 420], [418, 428], [422, 422], [425, 428], [428, 428], [430, 430]], \"head_scores\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['doc_key',\n",
       " 'sentences',\n",
       " 'speakers',\n",
       " 'clusters',\n",
       " 'sentence_map',\n",
       " 'subtoken_map',\n",
       " 'predicted_clusters',\n",
       " 'top_spans',\n",
       " 'head_scores']"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[k for k in output.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import CorefEvaluator\n",
    "from document import Document\n",
    "from evaluator import JsonEval\n",
    "from utils import flatten, tuplify_clusters\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_of_prev_sentences(sentence_index, sentence_map):\n",
    "    return len([idx for idx in sentence_map if idx < sentence_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_clusters(json_file):\n",
    "    clusters = json_file['predicted_clusters']  # clusters predicted by SpanBERT\n",
    "    sents = flatten(json_file['sentences'])     # text as word tokens\n",
    "    sents_map = json_file['sentence_map']             # a mapping of token to sent index\n",
    "    parsed_predictions = []\n",
    "    for pred in clusters:\n",
    "        parsed_cluster = []\n",
    "        for mention in pred:\n",
    "            m1, m2 = mention\n",
    "            # both mentions are in the same sentences, use m1 or m2\n",
    "            sentid = sents_map[m1]\n",
    "\n",
    "            prev_token_offset = length_of_prev_sentences(sentid, sents_map)\n",
    "            if False:\n",
    "                print(\"current:\", sentid)\n",
    "                print(\"prev sentences: {}\".format(prev_token_offset))\n",
    "                print(m1, m2)\n",
    "                print(sents[m1], sents[m2])\n",
    "                print()\n",
    "            start = m1 - prev_token_offset\n",
    "            end = m2 - prev_token_offset + 1  # PreCo has a +1 on end index\n",
    "            #print(\"({},{},{}): {}\".format(sentid, start, end, _sents[m1:m2+1]))\n",
    "            parsed_cluster.append([sentid, start, end])\n",
    "        parsed_predictions.append(parsed_cluster)\n",
    "    return parsed_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluated 100 documents with 4 metrics\n",
      "Running metric: muc\n",
      "Precision:\t0.48452883263009844\n",
      "Recall:\t\t0.33560642961519727\n",
      "F1 score:\t0.396546762589928\n",
      "-----------------------------------\n",
      "Running metric: b_cubed\n",
      "Precision:\t0.3767867951956681\n",
      "Recall:\t\t0.23517322097832055\n",
      "F1 score:\t0.2895946202572522\n",
      "-----------------------------------\n",
      "Running metric: ceafe\n",
      "Precision:\t0.44177369413259887\n",
      "Recall:\t\t0.05885753322293339\n",
      "F1 score:\t0.1038757011494286\n",
      "-----------------------------------\n",
      "Running metric: lea\n",
      "Precision:\t0.3377535237102746\n",
      "Recall:\t\t0.20643175249133142\n",
      "F1 score:\t0.25624747621361194\n",
      "-----------------------------------\n",
      "\n",
      "CoNLL-2012 F1 score: 0.2633390279988696\n",
      "Precision:\t0.0\n",
      "Recall:\t\t0.0\n",
      "F1 score:\t0.0\n"
     ]
    }
   ],
   "source": [
    "source_path = '../../data/PreCo/dev.jsonl'\n",
    "annotated_path = 'spanbert_annotated_data/preco_dev_spanbert_run_1.jsonl'\n",
    "\n",
    "source_key = \"mention_clusters\"\n",
    "\n",
    "scorer = CorefEvaluator()\n",
    "\n",
    "n = 0\n",
    "docs_to_eval = []\n",
    "with open(source_path, 'r') as source, open(annotated_path, 'r') as annotated:\n",
    "    for json_source, json_annot in zip(source, annotated):\n",
    "        n+=1\n",
    "        if n>100:\n",
    "            break\n",
    "        source_data = json.loads(json_source)\n",
    "        annot_data = json.loads(json_annot)\n",
    "        \n",
    "        # convert to tuples supported by evaluation script\n",
    "        gold = source_data[source_key]\n",
    "        pred = parse_clusters(annot_data)\n",
    "        \n",
    "        #if n==2:\n",
    "        doc = Document(pred, gold)  # a document parsing the data into mention objects\n",
    "        docs_to_eval.append(doc)\n",
    "            #print(pred)\n",
    "            #print(gold)\n",
    "        #    print(doc)\n",
    "            #break\n",
    "\n",
    "\n",
    "scorer.eval_documents(docs_to_eval)\n",
    "print(scorer)\n",
    "\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with open(source_path, 'r') as source:\n",
    "    # create an empty object containing gold + predictions\n",
    "    pred_obj = {\n",
    "        'predicted': []\n",
    "        'gold': \n",
    "    }\n",
    "    for jsonline in source.readlines():\n",
    "        as_json = json.loads(jsonline)\n",
    "        gold.append\n",
    "    with open(annotated_path, 'r') as annotated:\n",
    "\n",
    "        # parse annotated spanbert data in preco format\n",
    "        for jsonline in annotated.readlines():\n",
    "            as_json = json.loads(jsonline)\n",
    "            \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
